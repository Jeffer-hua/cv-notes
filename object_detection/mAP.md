#### 目标检测评价标准mAP
1.准确率,精确率,召回率概念。
>分类任务中，正类预测为正类为TP（True Positive）,正类预测为负类为FN（False Negative）,负类预测为负类为TN，负类预测为正类为FP。
>
>准确率（Accuracy）：所有预测中多少是预测正确的，(TP+TN)/(TP+TN+FP+FN).
>
>精确率(Precision):预测为正类的样本中有多少是真的正类，TP/(TP+FP).
>
>召回率(Recall):样本中的正类多少被预测正确了，TP/(TP+FN)


2.mAP产生与计算
>图像分类任务中，多用Precision当做评价标准，而目标检测任务中不单单是分类问题还有目标的定位，Precision即便是很高，可是如果Recall很低(即很多漏检),也是不合理的，不同任务对于Precision和Recall中的要求也是不一样的，从而产生了AP来评价一个目标检测模型的好坏，mAP即是所有类别AP的均值。
>
>首先通过计算IOU（prediction与GT的交并比）,判断检测结果是否正确。prediction为预测框的bbox，GT（GroundTruth为标注bbox）,VOC数据集设置IOU>0.5为TP，否则为FP
>
>两种计算AP的方法
>
>1.VOC2007之前，采用11-point interpolated average reecision。首先设定一组阈值[0,0.1..1]，range(0，1，0.1)，然后对于Recall大于每一个阈值，会得到一个最大Precision，通过这样子计算得出11个Precision,AP为这11个precision的均值。
>
>2.VOC2010以后，新的计算方法假设这N个样本中有M个正例，那么我们会得到M个recall(1/M,2/M..M/M),对于每个recall值r，我们可以计算对应(r`>r)的最大precision，绘制PR曲线，AP即为曲线下面积/recall个数。
>
>mAP就是对每一个类别求AP，再去计算AP的平均值。

3.mAP计算例子
>假设类别A的10个测试样本的score和GTlabel如下

id | score |  gt_label  
-|-|-
1 | 0.23 | 0 |
2 | 0.76 | 1 |
3 | 0.01 | 0 |
4 | 0.91 | 1 |
5 | 0.13 | 0 |
6 | 0.45 | 0 |
7 | 0.12 | 1 |
8 | 0.03 | 0 |
9 | 0.38 | 1 |
10 | 0.11 | 0 |
>根据score排序得

id | score |  gt_label  
-|-|-
4 | 0.91 | 1 |
2 | 0.76 | 1 |
6 | 0.45 | 0 |
9 | 0.38 | 1 |
1 | 0.23 | 0 |
5 | 0.13 | 0 |
7 | 0.12 | 1 |
10 | 0.11 | 0 |
8 | 0.03 | 0 |
3 | 0.01 | 0 |
>例如top-5中，P=TP/(TP+FP)=3/(3+2)=0.6,R=TP/(TP+FN)=3/(3+4)=3/7,当然一般求的是top-1到top-N（测试样本个数）的P和R。

>计算和绘图可得

top-N | Precision | Recall | Max P  
-|-|-|-
1 | 1 | 1/4 | 1 |
2 | 1 | 1/2 | 
3 | 2/3 | 1/2 | 1 |
4 | 3/4 | 3/4 |
5 | 3/5 | 3/4 |
6 | 1/2 | 3/4 | 3/4 |
7 | 4/7 | 1 |
8 | 1/2 | 1 |
9 | 4/9 | 1 |
10 | 2/5 | 1 | 4/7 |

>PR曲线图

>第一种计算方式:AP=(1+1+1+1+1+3/4+3/4+4/7+4/7+4/7+4/7)/11=0.79
>
>第二种计算方式:AP=(1+1+3/4+4/7)/4=0.83

